{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZPeew9bgk_zv",
        "outputId": "1f7a5dce-f85c-46a4-f908-4fd7d8e7e1cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepeval==3.7.0 in /usr/local/lib/python3.12/dist-packages (3.7.0)\n",
            "Requirement already satisfied: langchain==0.3.7 in /usr/local/lib/python3.12/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-core==0.3.17 in /usr/local/lib/python3.12/dist-packages (0.3.17)\n",
            "Requirement already satisfied: langchain-community==0.3.7 in /usr/local/lib/python3.12/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain-qdrant==0.2.0 in /usr/local/lib/python3.12/dist-packages (0.2.0)\n",
            "Requirement already satisfied: langchain-huggingface==0.1.1 in /usr/local/lib/python3.12/dist-packages (0.1.1)\n",
            "Requirement already satisfied: langchain-openai==0.2.3 in /usr/local/lib/python3.12/dist-packages (0.2.3)\n",
            "Requirement already satisfied: qdrant-client==1.11.0 in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: sentence-transformers==3.0.1 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pymupdf==1.24.7 in /usr/local/lib/python3.12/dist-packages (1.24.7)\n",
            "Requirement already satisfied: python-dotenv==1.1.1 in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: opentelemetry-api==1.37.0 in /usr/local/lib/python3.12/dist-packages (1.37.0)\n",
            "Requirement already satisfied: razdel==0.5.0 in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
            "Requirement already satisfied: yandex_cloud_ml_sdk==0.17.0 in /usr/local/lib/python3.12/dist-packages (0.17.0)\n",
            "Requirement already satisfied: mistralai==1.9.11 in /usr/local/lib/python3.12/dist-packages (1.9.11)\n",
            "Requirement already satisfied: pydantic==2.11.7 in /usr/local/lib/python3.12/dist-packages (2.11.7)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (3.13.2)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (0.75.0)\n",
            "Requirement already satisfied: click<8.3.0,>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (8.2.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (1.52.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.67.1 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (1.76.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (1.6.0)\n",
            "Requirement already satisfied: ollama in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (0.6.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (1.109.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (1.37.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (2.10.1)\n",
            "Requirement already satisfied: posthog<6.0.0,>=5.4.0 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (5.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (2.12.0)\n",
            "Requirement already satisfied: pyfiglet in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (1.0.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (8.4.2)\n",
            "Requirement already satisfied: pytest-asyncio in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: pytest-repeat in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: pytest-rerunfailures<13.0,>=12.0 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (12.0)\n",
            "Requirement already satisfied: pytest-xdist in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (3.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (2.32.4)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.6.0 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (2.46.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (75.2.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: tenacity<=10.0.0,>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (9.1.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9 in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from deepeval==3.7.0) (0.45.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.7) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.7) (2.0.35)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.7) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.7) (0.1.147)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.7) (1.26.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.17) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.17) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.17) (4.15.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.7) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.3.7) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface==0.1.1) (0.36.0)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface==0.1.1) (0.22.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface==0.1.1) (4.57.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.3) (0.12.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client==1.11.0) (1.71.2)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client==1.11.0) (0.28.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.12/dist-packages (from qdrant-client==1.11.0) (2.5.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.1) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.1) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.1) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==3.0.1) (11.3.0)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.6 in /usr/local/lib/python3.12/dist-packages (from pymupdf==1.24.7) (1.24.6)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api==1.37.0) (8.7.0)\n",
            "Requirement already satisfied: yandexcloud>=0.359.0 in /usr/local/lib/python3.12/dist-packages (from yandex_cloud_ml_sdk==0.17.0) (0.370.0)\n",
            "Requirement already satisfied: get-annotations in /usr/local/lib/python3.12/dist-packages (from yandex_cloud_ml_sdk==0.17.0) (0.1.2)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.12/dist-packages (from yandex_cloud_ml_sdk==0.17.0) (24.1.0)\n",
            "Requirement already satisfied: eval-type-backport>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from mistralai==1.9.11) (0.3.1)\n",
            "Requirement already satisfied: invoke<3.0.0,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from mistralai==1.9.11) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from mistralai==1.9.11) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mistralai==1.9.11) (0.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.7) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.11.7) (2.33.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval==3.7.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval==3.7.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval==3.7.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval==3.7.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval==3.7.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval==3.7.0) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.7) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.7) (0.9.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.0) (2.43.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.7.0) (15.0.1)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.12/dist-packages (from grpcio-tools>=1.41.0->qdrant-client==1.11.0) (5.29.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.11.0) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.11.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.11.0) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client==1.11.0) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client==1.11.0) (4.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.1) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.1) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.1) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.37.0) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.17) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.7) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.7) (1.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai->deepeval==3.7.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai->deepeval==3.7.0) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai->deepeval==3.7.0) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.0) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.7.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval==3.7.0) (0.58b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval==3.7.0) (1.17.0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval==3.7.0) (2.2.1)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval==3.7.0) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval==3.7.0) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->deepeval==3.7.0) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=13.6.0->deepeval==3.7.0) (4.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.7) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.3) (2025.11.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (3.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (3.5.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.39.0->langchain-huggingface==0.1.1) (0.7.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.9->deepeval==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: cryptography>=44.0.0 in /usr/local/lib/python3.12/dist-packages (from yandexcloud>=0.359.0->yandex_cloud_ml_sdk==0.17.0) (46.0.3)\n",
            "Requirement already satisfied: pyjwt<3,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from yandexcloud>=0.359.0->yandex_cloud_ml_sdk==0.17.0) (2.10.1)\n",
            "Requirement already satisfied: deprecated>=1.2.18 in /usr/local/lib/python3.12/dist-packages (from yandexcloud>=0.359.0->yandex_cloud_ml_sdk==0.17.0) (1.3.1)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic->deepeval==3.7.0) (0.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->deepeval==3.7.0) (3.0.3)\n",
            "Requirement already satisfied: execnet>=2.1 in /usr/local/lib/python3.12/dist-packages (from pytest-xdist->deepeval==3.7.0) (2.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==3.0.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==3.0.1) (3.6.0)\n",
            "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cryptography>=44.0.0->yandexcloud>=0.359.0->yandex_cloud_ml_sdk==0.17.0) (2.0.0)\n",
            "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated>=1.2.18->yandexcloud>=0.359.0->yandex_cloud_ml_sdk==0.17.0) (2.0.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.0) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.0) (4.9.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client==1.11.0) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client==1.11.0) (4.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.6.0->deepeval==3.7.0) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==3.0.1) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.7) (1.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->cryptography>=44.0.0->yandexcloud>=0.359.0->yandex_cloud_ml_sdk==0.17.0) (2.23)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.7.0) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install deepeval==3.7.0 \\\n",
        "              langchain==0.3.7 \\\n",
        "              langchain-core==0.3.17 \\\n",
        "              langchain-community==0.3.7 \\\n",
        "              langchain-qdrant==0.2.0 \\\n",
        "              langchain-huggingface==0.1.1 \\\n",
        "              langchain-openai==0.2.3 \\\n",
        "              qdrant-client==1.11.0 \\\n",
        "              sentence-transformers==3.0.1 \\\n",
        "              pymupdf==1.24.7 \\\n",
        "              python-dotenv==1.1.1 \\\n",
        "              opentelemetry-api==1.37.0 \\\n",
        "              razdel==0.5.0 \\\n",
        "              yandex_cloud_ml_sdk==0.17.0 \\\n",
        "              mistralai==1.9.11 \\\n",
        "              pydantic==2.11.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Rw3SqyMtfb3j"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import time\n",
        "from pathlib import Path\n",
        "import asyncio\n",
        "from typing import Any, Dict, Sequence, Optional, Union, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "from qdrant_client import QdrantClient, models\n",
        "from langchain_qdrant import Qdrant\n",
        "import deepeval\n",
        "from deepeval.models.base_model import DeepEvalBaseLLM\n",
        "from yandex_cloud_ml_sdk import YCloudML\n",
        "\n",
        "from langchain.schema import Document\n",
        "from langchain_core.language_models.llms import LLM, BaseCache\n",
        "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage\n",
        "from langchain_core.outputs import Generation, LLMResult\n",
        "from langchain_core.vectorstores.base import VectorStore\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.callbacks.manager import Callbacks\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "\n",
        "DATA_DIR = Path(\"/content/books\")\n",
        "YANDEX_API_KEY = userdata.get('YANDEX_API_KEY')\n",
        "YANDEX_FOLDER_ID = userdata.get('YANDEX_FOLDER_ID')\n",
        "OPENROUTER_API_KEY = userdata.get('openrouter_intuition')\n",
        "OPENROUTER_BASE_URL = userdata.get('openrouter_base_url')\n",
        "MY_QDRANT_URL = userdata.get('MY_QDRANT_URL')\n",
        "MY_QDRANT_KEY = userdata.get('MY_QDRANT_KEY')\n",
        "\n",
        "MAX_EMBEDDING_BATCH = 50\n",
        "QDRANT_BATCH_SIZE = 200\n",
        "QDRANT_TIMEOUT = 300\n",
        "QDRANT_MAX_RETRIES = 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOrkJOkOrhKM"
      },
      "source": [
        "# Yandex Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8bcJUThQsryl"
      },
      "outputs": [],
      "source": [
        "class YandexCloudEmbeddings(Embeddings):\n",
        "    \"\"\"–ö–ª–∞—Å—Å-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ Yandex Cloud, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å LangChain.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "          self,\n",
        "          folder_id: str,\n",
        "          api_key: str,\n",
        "          requests_per_second: int=9,\n",
        "          timeout: float=60.0\n",
        "        ):\n",
        "\n",
        "        self.sdk = YCloudML(\n",
        "            folder_id=folder_id,\n",
        "            auth=api_key\n",
        "        )\n",
        "        self.query_model = self.sdk.models.text_embeddings(\"query\")\n",
        "        self.doc_model = self.sdk.models.text_embeddings(\"doc\")\n",
        "        self.vector_size = 256\n",
        "        self.delay = 1.0 / requests_per_second\n",
        "        self.timeout = timeout\n",
        "\n",
        "    def _rate_limited_run(self, model, text: str) -> List[float]:\n",
        "        \"\"\"–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏.\"\"\"\n",
        "        result = model.run(text, timeout=self.timeout)\n",
        "        time.sleep(self.delay)\n",
        "        return result\n",
        "\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        \"\"\"–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏.\"\"\"\n",
        "        return [self._rate_limited_run(self.doc_model, text) for text in texts]\n",
        "\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        \"\"\"–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞.\"\"\"\n",
        "        return self._rate_limited_run(self.query_model, text)\n",
        "\n",
        "    def encode(self, texts: List[str], **kwargs) -> np.ndarray:\n",
        "        \"\"\"–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º SentenceTransformer.\"\"\"\n",
        "        embeddings = self.embed_documents(texts)\n",
        "        return np.array(embeddings)\n",
        "\n",
        "\n",
        "embeddings = YandexCloudEmbeddings(\n",
        "    folder_id=YANDEX_FOLDER_ID,\n",
        "    api_key=YANDEX_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cceOqshIYa8k",
        "outputId": "00ceccc2-e22b-457b-b537-1c839a0bb176"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 256)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector = embeddings.encode([\"example\"])\n",
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8viR5_dfV37"
      },
      "source": [
        "# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NfB9GmpxUzMJ"
      },
      "outputs": [],
      "source": [
        "def add_documents_in_batches(\n",
        "    qdrant_store: Qdrant,\n",
        "    documents: List[Document],\n",
        "    batch_size: int=QDRANT_BATCH_SIZE\n",
        "  ):\n",
        "\n",
        "    total_docs = len(documents)\n",
        "    added_docs = 0\n",
        "\n",
        "    for i in range(0, total_docs, batch_size):\n",
        "        batch = documents[i:i + batch_size]\n",
        "        retry_count = 0\n",
        "\n",
        "        while retry_count < QDRANT_MAX_RETRIES:\n",
        "            try:\n",
        "                qdrant_store.add_documents(batch)\n",
        "                added_docs += len(batch)\n",
        "                print(f\"[OK] Qdrant: –î–æ–±–∞–≤–ª–µ–Ω–æ {added_docs}/{total_docs} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\")\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                retry_count += 1\n",
        "                print(f\"[FAIL] Qdrant: –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –±–∞—Ç—á–∞ {i//batch_size + 1}, –ø–æ–ø—ã—Ç–∫–∞ {retry_count}/{QDRANT_MAX_RETRIES}: {e}\")\n",
        "                time.sleep(5)\n",
        "                if retry_count >= QDRANT_MAX_RETRIES:\n",
        "                    raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Axed7esyjyzI"
      },
      "outputs": [],
      "source": [
        "def chunk_upload_qdrant(\n",
        "    pdf_path: str,\n",
        "    qdrant_store: Qdrant,\n",
        "    splitter: RecursiveCharacterTextSplitter\n",
        "):\n",
        "\n",
        "    if not os.path.exists(pdf_path):\n",
        "        raise FileNotFoundError(f\"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pdf_path}\")\n",
        "\n",
        "    loader = PyMuPDFLoader(pdf_path)\n",
        "    pdf_name = os.path.basename(pdf_path)\n",
        "    docs = loader.load()\n",
        "    for doc in docs:\n",
        "        doc.metadata[\"source\"] = pdf_name\n",
        "\n",
        "    chunks = splitter.split_documents(docs)\n",
        "    print(f\"{len(chunks)} —á–∞–Ω–∫–æ–≤\")\n",
        "\n",
        "    add_documents_in_batches(qdrant_store, chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2z5frWkKfqy"
      },
      "source": [
        "# Yandex GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3tR0uokuarYY"
      },
      "outputs": [],
      "source": [
        "class YandexGPT(LLM):\n",
        "    \"\"\"LangChain –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å YandexGPT.\"\"\"\n",
        "\n",
        "    model_name: str = \"yandexgpt\"\n",
        "    temperature: float = 0.0\n",
        "    max_tokens: int = 2000\n",
        "    folder_id: str = YANDEX_FOLDER_ID\n",
        "    api_key: str = YANDEX_API_KEY\n",
        "    sdk: Any = None\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.sdk = YCloudML(\n",
        "            folder_id=self.folder_id,\n",
        "            auth=self.api_key,\n",
        "        )\n",
        "\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∏–ø LLM.\"\"\"\n",
        "        return \"yandexgpt\"\n",
        "\n",
        "    def _convert_messages_to_yandex_format(\n",
        "        self,\n",
        "        messages: Sequence[BaseMessage]\n",
        "      ) -> List[Dict[str, str]]:\n",
        "        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è LangChain –≤ —Ñ–æ—Ä–º–∞—Ç YandexGPT.\"\"\"\n",
        "\n",
        "        yandex_messages = []\n",
        "        for message in messages:\n",
        "            if isinstance(message, SystemMessage):\n",
        "                yandex_messages.append({\"role\": \"system\", \"text\": message.content})\n",
        "            elif isinstance(message, HumanMessage):\n",
        "                yandex_messages.append({\"role\": \"user\", \"text\": message.content})\n",
        "        return yandex_messages\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "        \"\"\"–í—ã–∑—ã–≤–∞–µ—Ç YandexGPT —Å –∑–∞–¥–∞–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º.\"\"\"\n",
        "\n",
        "        messages = [{\"role\": \"user\", \"text\": prompt}]\n",
        "\n",
        "        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å\n",
        "        if \"system_prompt\" in kwargs:\n",
        "            messages.insert(0, {\"role\": \"system\", \"text\": kwargs[\"system_prompt\"]})\n",
        "\n",
        "        try:\n",
        "            result = (\n",
        "                self.sdk.models.completions(self.model_name)\n",
        "                .configure(\n",
        "                    temperature=kwargs.get(\"temperature\", self.temperature),\n",
        "                    max_tokens=kwargs.get(\"max_tokens\", self.max_tokens)\n",
        "                )\n",
        "                .run(messages)\n",
        "            )\n",
        "\n",
        "            if result:\n",
        "                return result[0].text\n",
        "\n",
        "            return \"–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞\"\n",
        "        except Exception as e:\n",
        "            raise\n",
        "\n",
        "\n",
        "    def _generate(\n",
        "        self,\n",
        "        prompts: List[str],\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> LLMResult:\n",
        "        \"\"\"–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã –Ω–∞ –ø—Ä–æ–º–ø—Ç—ã.\"\"\"\n",
        "        generations = []\n",
        "        for prompt in prompts:\n",
        "            messages = [{\"role\": \"user\", \"text\": prompt}]\n",
        "\n",
        "            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å\n",
        "            if \"system_prompt\" in kwargs:\n",
        "                messages.insert(0, {\"role\": \"system\", \"text\": kwargs[\"system_prompt\"]})\n",
        "\n",
        "            result = (\n",
        "                self.sdk.models.completions(self.model_name)\n",
        "                .configure(\n",
        "                    temperature=kwargs.get(\"temperature\", self.temperature),\n",
        "                    max_tokens=kwargs.get(\"max_tokens\", self.max_tokens)\n",
        "                )\n",
        "                .run(messages)\n",
        "            )\n",
        "\n",
        "            if result:\n",
        "                text = result[0].text\n",
        "            else:\n",
        "                text = \"–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞\"\n",
        "\n",
        "            generations.append([Generation(text=text)])\n",
        "\n",
        "        return LLMResult(generations=generations)\n",
        "\n",
        "\n",
        "    def invoke(\n",
        "        self,\n",
        "        input: str | BaseMessage | List[BaseMessage],\n",
        "        config: Optional[Dict[str, Any]] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "        \"\"\"–í—ã–∑—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –∑–∞–¥–∞–Ω–Ω—ã–º –≤–≤–æ–¥–æ–º.\"\"\"\n",
        "\n",
        "        if isinstance(input, str):\n",
        "            messages = [{\"role\": \"user\", \"text\": input}]\n",
        "\n",
        "        elif isinstance(input, BaseMessage):\n",
        "            messages = [{\"role\": \"user\", \"text\": input.content}]\n",
        "\n",
        "        else:\n",
        "            messages = self._convert_messages_to_yandex_format(input)\n",
        "\n",
        "        try:\n",
        "            result = (\n",
        "                self.sdk.models.completions(self.model_name)\n",
        "                .configure(\n",
        "                    temperature=kwargs.get(\"temperature\", self.temperature),\n",
        "                    max_tokens=kwargs.get(\"max_tokens\", self.max_tokens)\n",
        "                )\n",
        "                .run(messages)\n",
        "            )\n",
        "\n",
        "            if result:\n",
        "                return result[0].text\n",
        "\n",
        "            return \"–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞\"\n",
        "        except Exception as e:\n",
        "            raise\n",
        "\n",
        "\n",
        "    async def ainvoke(\n",
        "        self,\n",
        "        input: str | BaseMessage | List[BaseMessage],\n",
        "        config: Optional[Dict[str, Any]] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "        \"\"\"–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤—ã–∑—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –∑–∞–¥–∞–Ω–Ω—ã–º –≤–≤–æ–¥–æ–º.\"\"\"\n",
        "\n",
        "        if isinstance(input, str):\n",
        "            messages = [{\"role\": \"user\", \"text\": input}]\n",
        "\n",
        "        elif isinstance(input, BaseMessage):\n",
        "            messages = [{\"role\": \"user\", \"text\": input.content}]\n",
        "\n",
        "        else:\n",
        "            messages = self._convert_messages_to_yandex_format(input)\n",
        "\n",
        "        try:\n",
        "            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∑–∞–ø—Ä–æ—Å–∞\n",
        "            completion = (\n",
        "                self.sdk.models.completions(self.model_name)\n",
        "                .configure(\n",
        "                    temperature=kwargs.get(\"temperature\", self.temperature),\n",
        "                    max_tokens=kwargs.get(\"max_tokens\", self.max_tokens)\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π API-–∑–∞–ø—Ä–æ—Å –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ\n",
        "            loop = asyncio.get_event_loop()\n",
        "            result = await loop.run_in_executor(\n",
        "                None,\n",
        "                lambda: completion.run(messages)\n",
        "            )\n",
        "\n",
        "            if result:\n",
        "                text_result = result[0].text\n",
        "                return text_result\n",
        "\n",
        "            return \"–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞\"\n",
        "        except Exception as e:\n",
        "            raise\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Dict[str, Any]:\n",
        "        \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É—é—â–∏–µ –º–æ–¥–µ–ª—å.\"\"\"\n",
        "        return {\n",
        "            \"model_name\": self.model_name,\n",
        "            \"temperature\": self.temperature,\n",
        "            \"max_tokens\": self.max_tokens,\n",
        "            \"folder_id\": self.folder_id\n",
        "        }\n",
        "\n",
        "\n",
        "llm = YandexGPT()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WoSvtVTUh-LP",
        "outputId": "2b7d1570-d36d-4dd9-96a8-ce469c025ea0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ß–µ–º —è –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å?'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"–ü—Ä–∏–≤–µ—Ç\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiEU5hWqiJLy"
      },
      "source": [
        "# Other LLMs Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JE9RsjioL9o6"
      },
      "outputs": [],
      "source": [
        "openrouter_llm_temperature = 0.0\n",
        "openrouter_llm_max_tokens = 2000\n",
        "rag_llm_model = \"deepseek/deepseek-chat-v3.1\"\n",
        "\n",
        "ChatOpenAI.model_rebuild()\n",
        "llm = ChatOpenAI(\n",
        "    model=rag_llm_model,\n",
        "    openai_api_key=OPENROUTER_API_KEY,\n",
        "    openai_api_base=OPENROUTER_BASE_URL,\n",
        "    temperature=openrouter_llm_temperature,\n",
        "    max_tokens=openrouter_llm_max_tokens,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeQLu3epOynH",
        "outputId": "92709f24-05e6-4b2e-aaee-39441c9f5a07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='–ü—Ä–∏–≤–µ—Ç! üòä –ö–∞–∫ —è –º–æ–≥—É –ø–æ–º–æ—á—å –≤–∞–º —Å–µ–≥–æ–¥–Ω—è?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 8, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'video_tokens': 0}, 'cost': 1.516e-05, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 2.16e-06, 'upstream_inference_completions_cost': 1.3e-05}}, 'model_name': 'deepseek/deepseek-chat-v3.1', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a769d9f8-6ef2-46dc-ac81-a4cdd1ed4445-0', usage_metadata={'input_tokens': 8, 'output_tokens': 13, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"–ü—Ä–∏–≤–µ—Ç!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToqsA4DmiNWz"
      },
      "source": [
        "# RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "20vGJLWNif0F"
      },
      "outputs": [],
      "source": [
        "class RAG:\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      llm: LLM,\n",
        "      vector_store: VectorStore,\n",
        "      top_k_docs: int = 5,\n",
        "    ):\n",
        "\n",
        "    self.llm = llm\n",
        "    self.vector_store = vector_store\n",
        "    self.top_k_docs = top_k_docs\n",
        "    self.prompt = PromptTemplate(\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "        template=\"\"\"\n",
        "          –¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä—É—Å—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ.\n",
        "          –û—Ç–≤–µ—Ç—å —Ç–æ—á–Ω–æ –∏ –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω–æ–≥–æ –Ω–∏–∂–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n",
        "\n",
        "          –ö–æ–Ω—Ç–µ–∫—Å—Ç:\n",
        "          {context}\n",
        "\n",
        "          –í–æ–ø—Ä–æ—Å:\n",
        "          {question}\n",
        "\n",
        "          –°—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞\n",
        "          1. –Ø—Å–Ω—ã–π, —ç–Ω–µ—Ä–≥–∏—á–Ω—ã–π —Ç–æ–Ω, –æ–±—Ä–∞–∑–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã.\n",
        "          2. –ü–∏—à–∏ —è—Å–Ω–æ, –ø–æ-—Ä—É—Å—Å–∫–∏, –±–µ–∑ –ª–∏—à–Ω–µ–π –≤–æ–¥—ã.\n",
        "          3. –û—Ç–≤–µ—á–∞–π –ø–æ–¥—Ä–æ–±–Ω–æ.\n",
        "\n",
        "          –û—Ç–≤–µ—Ç:\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "  def retrieve_documents(\n",
        "      self,\n",
        "      question: str,\n",
        "      source_name: str\n",
        "    ):\n",
        "\n",
        "    retriever = self.vector_store.as_retriever(\n",
        "        search_kwargs={\n",
        "            \"filter\": {\n",
        "                \"source\": source_name\n",
        "            },\n",
        "            \"k\": self.top_k_docs\n",
        "        }\n",
        "    )\n",
        "    relevant_docs = retriever.invoke(question)\n",
        "    return relevant_docs\n",
        "\n",
        "\n",
        "  def generate_answer(\n",
        "      self,\n",
        "      question: str,\n",
        "      relevant_docs: List[Document]\n",
        "    ):\n",
        "\n",
        "    context = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
        "\n",
        "    prompt = self.prompt.format(\n",
        "        context=context,\n",
        "        question=question\n",
        "    )\n",
        "\n",
        "    answer = self.llm.invoke(prompt)\n",
        "    return answer\n",
        "\n",
        "\n",
        "  def run_rag_pipeline(\n",
        "      self,\n",
        "      question: str,\n",
        "      source_name: str\n",
        "    ):\n",
        "\n",
        "    relevant_docs = self.retrieve_documents(\n",
        "        question=question,\n",
        "        source_name=source_name\n",
        "    )\n",
        "\n",
        "    answer = self.generate_answer(\n",
        "        question=question,\n",
        "        relevant_docs=relevant_docs\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"answer\": answer,\n",
        "        \"context\": [str(doc.page_content) for doc in relevant_docs]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcVfxFrqhwlo"
      },
      "source": [
        "# –û—Ü–µ–Ω–∫–∞ RAG —Å –ø–æ–º–æ—â—å—é DeepEval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gV3UFo6YAhIf"
      },
      "outputs": [],
      "source": [
        "ChatOpenAI.model_rebuild()\n",
        "scorer_llm_model = \"openai/gpt-4o-mini\"\n",
        "\n",
        "class ScorerLLM(DeepEvalBaseLLM):\n",
        "    def __init__(self):\n",
        "      self._client = ChatOpenAI(\n",
        "          model=scorer_llm_model,\n",
        "          openai_api_key=OPENROUTER_API_KEY,\n",
        "          openai_api_base=OPENROUTER_BASE_URL,\n",
        "          temperature=0.0,\n",
        "          seed=42\n",
        "      )\n",
        "      self._model = scorer_llm_model\n",
        "\n",
        "\n",
        "    def load_model(self):\n",
        "      return self._client\n",
        "\n",
        "    def  get_model_name(self):\n",
        "      return self._model\n",
        "\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "      messages = [HumanMessage(content=prompt)]\n",
        "      response = self._client.invoke(messages)\n",
        "      return response.content\n",
        "\n",
        "\n",
        "\n",
        "    async def a_generate(self, prompt: str) -> str:\n",
        "      return self.generate(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vYV3ByMGmiYa"
      },
      "outputs": [],
      "source": [
        "def create_deepeval_dataset(dataset, rag):\n",
        "    test_cases = []\n",
        "\n",
        "    for i in tqdm(range(len(dataset))):\n",
        "        entry = dataset[i]\n",
        "        source_name = entry['source_name']\n",
        "        question = entry['question']\n",
        "        answer = entry['answer']\n",
        "\n",
        "        result = rag.run_rag_pipeline(\n",
        "            question, source_name\n",
        "        )\n",
        "        context, rag_response = result['context'], result['answer']\n",
        "        test_case = deepeval.test_case.LLMTestCase(\n",
        "            input=question,\n",
        "            actual_output=rag_response,\n",
        "            expected_output=answer,\n",
        "            retrieval_context=context\n",
        "        )\n",
        "\n",
        "        test_cases.append(test_case)\n",
        "\n",
        "    return test_cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G9ETROZ6vP8"
      },
      "source": [
        "# Evaluation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PwAlclXnIHKR"
      },
      "outputs": [],
      "source": [
        "def get_metrics_single_book(\n",
        "        source_name: str,\n",
        "        eval_res_data: list,\n",
        "        raw_metrics_save_path: str,\n",
        "        chunk_size: int,\n",
        "        overlap: int,\n",
        "        topk: int,\n",
        "        llm: str,\n",
        "        embeddings_model: str,\n",
        "        embedding_size: int\n",
        "  ) -> pd.DataFrame:\n",
        "\n",
        "    rows = [\n",
        "        [item for tup in sublist for item in tup]\n",
        "        for sublist in eval_res_data\n",
        "    ]\n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        rows,\n",
        "        columns=[\"is_success_answer_relevant\", \"answer_relevant_score\", \"answer_relevant_thr\",\n",
        "                 \"is_success_contextuall_recall\", \"contextuall_recall_score\", \"contextuall_recall_thr\",\n",
        "                 \"is_success_ans_faithfulness\", \"answer_faithfulness_score\", \"answer_faithfulness_thr\"\n",
        "        ]\n",
        "    )\n",
        "    df[\"source_name\"] = len(df) * [source_name]\n",
        "    df[\"chunk_size\"] = len(df) * [chunk_size]\n",
        "    df[\"overlap\"] = len(df) * [overlap]\n",
        "    df[\"topk\"] = len(df) * [topk]\n",
        "    df[\"llm\"] = len(df) * [llm]\n",
        "    df[\"embeddings_model\"] = len(df) * [embeddings_model]\n",
        "    df[\"embedding_size\"] = len(df) * [embedding_size]\n",
        "    df.to_csv(raw_metrics_save_path, index=False)\n",
        "\n",
        "\n",
        "def get_all_metrics(\n",
        "    raw_metrics_dfs_dir: str,\n",
        "    detail_metrics_save_path: str,\n",
        "    compressed_metrics_save_path: str\n",
        "):\n",
        "    df_names = os.listdir(raw_metrics_dfs_dir)\n",
        "    full_metrics_df = pd.DataFrame()\n",
        "\n",
        "    for df_name in df_names:\n",
        "        df = pd.read_csv(f\"{raw_metrics_dfs_dir}/{df_name}\")\n",
        "        full_metrics_df = pd.concat([full_metrics_df, df])\n",
        "    full_metrics_df.to_csv(detail_metrics_save_path, index=False)\n",
        "\n",
        "    agg_df = full_metrics_df.groupby('source_name').agg({\n",
        "        'is_success_answer_relevant': 'mean',\n",
        "        'is_success_contextuall_recall': 'mean',\n",
        "        'is_success_ans_faithfulness': 'mean',\n",
        "        'chunk_size': 'first',\n",
        "        'overlap': 'first',\n",
        "        'topk': 'first',\n",
        "        'llm': 'first',\n",
        "        'embeddings_model': 'first',\n",
        "        'embedding_size': 'first',\n",
        "    }).reset_index()\n",
        "    agg_df.to_csv(compressed_metrics_save_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CvBPF8_boDuG"
      },
      "outputs": [],
      "source": [
        "def run_evaluation_pipeline(\n",
        "    base_dir: str,\n",
        "    book_golden_dict: dict,\n",
        "    embeddings,\n",
        "    MY_QDRANT_URL: str,\n",
        "    MY_QDRANT_KEY: str,\n",
        "    chunk_sizes: List[int],\n",
        "    overlaps: List[int],\n",
        "    topk_docs_rels: List[int],\n",
        "    llm_test_name: str,\n",
        "    embeddings_model_name: str,\n",
        "    embedding_size: int,\n",
        "    retry_count: int = 10,\n",
        "    raw_metrics_dir: str = \"raw_metrics\",\n",
        "    computed_metrics_dir: str = \"computed_metrics\",\n",
        "    compressed_metrics_dir: str = \"compressed_metrics\",\n",
        "    computed_filename: str = \"computed.csv\",\n",
        "    compressed_filename: str = \"compressed.csv\"\n",
        "):\n",
        "    client = QdrantClient(url=MY_QDRANT_URL, api_key=MY_QDRANT_KEY)\n",
        "    llm = YandexGPT()\n",
        "    scorer = ScorerLLM()\n",
        "\n",
        "    os.makedirs(os.path.join(base_dir, llm_test_name), exist_ok=True)\n",
        "\n",
        "    for chunk_size in chunk_sizes:\n",
        "        for overlap in overlaps:\n",
        "            for topk_docs_rel in topk_docs_rels:\n",
        "\n",
        "                print(f\"Test params: ch{chunk_size}_ov{overlap}_topk{topk_docs_rel}\")\n",
        "                cur_save_dir = os.path.join(\n",
        "                    base_dir,\n",
        "                    llm_test_name,\n",
        "                    f\"{llm_test_name}_embmodel_{embeddings_model_name}_ch{chunk_size}_ov{overlap}_topk{topk_docs_rel}\"\n",
        "                )\n",
        "                os.makedirs(cur_save_dir, exist_ok=True)\n",
        "\n",
        "                collection_name = f\"test_collection_ch{chunk_size}_ov{overlap}_topk{topk_docs_rel}\"\n",
        "                existing_collections = [c.name for c in client.get_collections().collections]\n",
        "\n",
        "                if collection_name not in existing_collections:\n",
        "                    client.create_collection(\n",
        "                        collection_name=collection_name,\n",
        "                        vectors_config=models.VectorParams(\n",
        "                            size=embedding_size,\n",
        "                            distance=models.Distance.COSINE\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                client.create_payload_index(\n",
        "                    collection_name=collection_name,\n",
        "                    field_name=\"metadata.source\",\n",
        "                    field_schema=models.PayloadSchemaType.KEYWORD\n",
        "                )\n",
        "\n",
        "                qdrant_store = Qdrant(\n",
        "                    client=client,\n",
        "                    collection_name=collection_name,\n",
        "                    embeddings=embeddings\n",
        "                )\n",
        "                rag = RAG(\n",
        "                    llm=llm,\n",
        "                    vector_store=qdrant_store,\n",
        "                    top_k_docs=topk_docs_rel\n",
        "                )\n",
        "\n",
        "                for book_name, (book_path, golden_path) in book_golden_dict.items():\n",
        "                    splitter = RecursiveCharacterTextSplitter(\n",
        "                        chunk_size=chunk_size,\n",
        "                        chunk_overlap=overlap,\n",
        "                        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
        "                        length_function=len,\n",
        "                        is_separator_regex=False,\n",
        "                        strip_whitespace=True\n",
        "                    )\n",
        "\n",
        "                    pickled_test_cases_path = os.path.join(\n",
        "                        cur_save_dir, f\"{book_name.rpartition('.')[0]}.pkl\"\n",
        "                    )\n",
        "\n",
        "                    if not os.path.exists(pickled_test_cases_path):\n",
        "                        chunk_upload_qdrant(\n",
        "                            pdf_path=book_path,\n",
        "                            qdrant_store=qdrant_store,\n",
        "                            splitter=splitter\n",
        "                        )\n",
        "\n",
        "                    with open(golden_path, 'r', encoding='utf-8') as f:\n",
        "                        dataset = json.load(f)[\"dataset\"]\n",
        "                    for elem in dataset:\n",
        "                        elem[\"source_name\"] = book_name\n",
        "\n",
        "                    if os.path.exists(pickled_test_cases_path):\n",
        "                        print(\"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã —Ä–∞–Ω–µ–µ\")\n",
        "                        with open(pickled_test_cases_path, 'rb') as f:\n",
        "                            test_cases = pickle.load(f)\n",
        "                    else:\n",
        "                        test_cases = create_deepeval_dataset(dataset, rag)\n",
        "                        with open(pickled_test_cases_path, 'wb') as f:\n",
        "                            pickle.dump(test_cases, f)\n",
        "\n",
        "                    data_eval_pickle = os.path.join(\n",
        "                        cur_save_dir, f\"metrics_{book_name.rpartition('.')[0]}.pkl\"\n",
        "                    )\n",
        "\n",
        "                    eval_res = None\n",
        "                    if os.path.exists(data_eval_pickle):\n",
        "                        print(\"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞–Ω–µ–µ\")\n",
        "                        with open(data_eval_pickle, 'rb') as f:\n",
        "                            eval_res = pickle.load(f)\n",
        "                    else:\n",
        "                        for retry in range(retry_count):\n",
        "                            try:\n",
        "                                eval_res = deepeval.evaluate(\n",
        "                                    test_cases=test_cases,\n",
        "                                    metrics=[\n",
        "                                        deepeval.metrics.AnswerRelevancyMetric(model=scorer, async_mode=False),\n",
        "                                        deepeval.metrics.ContextualRecallMetric(model=scorer, async_mode=False),\n",
        "                                        deepeval.metrics.FaithfulnessMetric(model=scorer, async_mode=False),\n",
        "                                    ],\n",
        "                                )\n",
        "                                if eval_res:\n",
        "                                    with open(data_eval_pickle, 'wb') as f:\n",
        "                                        pickle.dump(eval_res, f)\n",
        "                                    break\n",
        "                            except Exception as ex:\n",
        "                                print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ (–ø–æ–ø—ã—Ç–∫–∞ {retry + 1}): {ex}\")\n",
        "                                continue\n",
        "\n",
        "                    if eval_res is None:\n",
        "                        print(f\"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ü–µ–Ω–∏—Ç—å {book_name} ‚Äî –ø—Ä–æ–ø—É—Å–∫.\")\n",
        "                        continue\n",
        "\n",
        "\n",
        "                    data = [\n",
        "                        [\n",
        "                            (md.success, md.score, md.threshold)\n",
        "                            for md in test_result.metrics_data\n",
        "                        ]\n",
        "                        for test_result in eval_res.test_results\n",
        "                    ]\n",
        "\n",
        "                    for subdir in [raw_metrics_dir, computed_metrics_dir, compressed_metrics_dir]:\n",
        "                        os.makedirs(os.path.join(cur_save_dir, subdir), exist_ok=True)\n",
        "\n",
        "                    raw_metrics_path = os.path.join(\n",
        "                        cur_save_dir, raw_metrics_dir, f\"raw_{book_name.rpartition('.')[0]}.csv\"\n",
        "                    )\n",
        "                    computed_metrics_path = os.path.join(\n",
        "                        cur_save_dir, computed_metrics_dir, computed_filename\n",
        "                    )\n",
        "                    compressed_metrics_path = os.path.join(\n",
        "                        cur_save_dir, compressed_metrics_dir, compressed_filename\n",
        "                    )\n",
        "\n",
        "                    get_metrics_single_book(\n",
        "                        source_name=book_name,\n",
        "                        eval_res_data=data,\n",
        "                        raw_metrics_save_path=raw_metrics_path,\n",
        "                        chunk_size=chunk_size,\n",
        "                        overlap=overlap,\n",
        "                        topk=topk_docs_rel,\n",
        "                        llm=llm_test_name,\n",
        "                        embeddings_model=embeddings_model_name,\n",
        "                        embedding_size=embedding_size\n",
        "                    )\n",
        "\n",
        "                get_all_metrics(\n",
        "                    raw_metrics_dfs_dir=os.path.join(cur_save_dir, raw_metrics_dir),\n",
        "                    detail_metrics_save_path=computed_metrics_path,\n",
        "                    compressed_metrics_save_path=compressed_metrics_path\n",
        "                )\n",
        "\n",
        "                client.delete_collection(collection_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mGpeapajo8pr"
      },
      "outputs": [],
      "source": [
        "base_dir = \"/content/drive/MyDrive/rag-evaluation\"\n",
        "books_dir = f\"{base_dir}/books\"\n",
        "books = os.listdir(books_dir)\n",
        "golden_data = f\"{base_dir}/golden_data\"\n",
        "book_golden_dict = {book: [f\"{books_dir}/{book}\", f\"{golden_data}/{book.rpartition('.')[0]}.json\"] for book in books}\n",
        "\n",
        "chunk_sizes = [2000, 1500, 1000]\n",
        "overlaps = [200, 150, 100]\n",
        "topk_docs_rels = [10, 5]\n",
        "\n",
        "llm_test_name = \"yagpt\"\n",
        "embeddings_model_name = \"ya_embeddings\"\n",
        "embedding_size = 256\n",
        "\n",
        "run_evaluation_pipeline(\n",
        "    base_dir=base_dir,\n",
        "    book_golden_dict=book_golden_dict,\n",
        "    embeddings=embeddings,\n",
        "    MY_QDRANT_URL=MY_QDRANT_URL,\n",
        "    MY_QDRANT_KEY=MY_QDRANT_KEY,\n",
        "    chunk_sizes=chunk_sizes,\n",
        "    overlaps=overlaps,\n",
        "    topk_docs_rels=topk_docs_rels,\n",
        "    llm_test_name=llm_test_name,\n",
        "    embeddings_model_name=embeddings_model_name,\n",
        "    embedding_size=embedding_size\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
